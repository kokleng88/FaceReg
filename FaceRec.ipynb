{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection and Recognition\n",
    "=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code below is a simple face detection and drawing an ellipse over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Face and draw ellipse on sample image\n",
    "\n",
    "import cv2\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "OUTPUT_SIZE_WIDTH = 900\n",
    "OUTPUT_SIZE_HEIGHT = 600\n",
    "\n",
    "image = cv2.imread(r'C:\\\\Personal_Projects\\\\facereg\\\\Mona_Lisa.jpg')\n",
    "baseImage = image\n",
    "resultImage = baseImage.copy()\n",
    "\n",
    "gray_image=cv2.cvtColor(baseImage,cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray_image,1.1,8)\n",
    "eyes = eyeCascade.detectMultiScale(gray_image,1.1,8)\n",
    "\n",
    "maxArea=0\n",
    "x=0\n",
    "y=0\n",
    "w=0\n",
    "h=0\n",
    "\n",
    "maxArea2=0\n",
    "x2=0\n",
    "y2=0\n",
    "w2=0\n",
    "h2=0\n",
    "\n",
    "faceColor = (0,100,255)\n",
    "eyeColor = (0,200,255)\n",
    "\n",
    "for (_x,_y,_w,_h) in faces:\n",
    "    if _w * _h > maxArea:\n",
    "        x=_x\n",
    "        y=_y\n",
    "        w=_w\n",
    "        h=_h\n",
    "    maxArea=w*h\n",
    "    cv2.ellipse(resultImage, (x+int(round(w/2,0)),y+int(round(h/2,0))), (int(round(w/2,0)),int(round(h/2,0))), 0,0,360,faceColor,2)\n",
    "    #cv2.rectangle(resultImage, (x, y), (x+w, y+h), faceColor, 2)\n",
    "\n",
    "for (_x2, _y2,_w2,_h2) in eyes:\n",
    "    if _w2 * _h2 > maxArea2:\n",
    "        x2=_x2\n",
    "        y2=_y2\n",
    "        w2=_w2\n",
    "        h2=_h2\n",
    "    maxArea2=w2*h2\n",
    "    cv2.ellipse(resultImage, (x2+int(round(w2/2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) #left eye\n",
    "    cv2.ellipse(resultImage, (x2+int(round(w2*2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) #Right eye\n",
    "    #cv2.rectangle(resultImage,(x2-2,y2-2),(x2+w2+2,y2+h2+2),eyeColor,2)\n",
    "\n",
    "cv2.imshow('Sample image - Press any key to quit',resultImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code below is a simple face and eye detection from camera source and drawing ellipses over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Following code is edited to track face and eyes (from camera) using ellipse\n",
    "\n",
    "import cv2\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "OUTPUT_SIZE_WIDTH = 900\n",
    "OUTPUT_SIZE_HEIGHT = 600\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "while(True):\n",
    "    faceColor = (0,100,255)\n",
    "    eyeColor = (0,200,255)\n",
    "\n",
    "    rc, fullSizeBaseImage = capture.read()\n",
    "    fullSizeBaseImage = cv2.flip(fullSizeBaseImage,1)\n",
    "    baseImage = fullSizeBaseImage\n",
    "\n",
    "    pressedKey = cv2.waitKey(2)\n",
    "    if(pressedKey == ord(' ')) | (pressedKey == 27):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        #exit(0)\n",
    "    resultImage = baseImage.copy()\n",
    "\n",
    "    gray_image=cv2.cvtColor(baseImage,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray_image,1.1,8)\n",
    "    eyes = eyeCascade.detectMultiScale(gray_image,1.1,8)\n",
    "\n",
    "    maxArea=0\n",
    "    x=0\n",
    "    y=0\n",
    "    w=0\n",
    "    h=0\n",
    "    \n",
    "    maxArea2=0\n",
    "    x2=0\n",
    "    y2=0\n",
    "    w2=0\n",
    "    h2=0\n",
    "\n",
    "    for (_x, _y,_w,_h) in faces:\n",
    "        if _w * _h > maxArea:\n",
    "            x=_x\n",
    "            y=_y\n",
    "            w=_w\n",
    "            h=_h\n",
    "        maxArea=w*h\n",
    "        \n",
    "    if maxArea>0:\n",
    "       # cv2.rectangle(resultImage,(x-10,y-20),(x+w+10,y+h+10),rectangleColor,2)\n",
    "       cv2.ellipse(resultImage, (x+int(round(w/2,0)),y+int(round(h/2,0))), (int(round(w/2,0)),int(round(h/2,0))), 0,0,360,faceColor,2)\n",
    "     \n",
    "    for (_x2, _y2,_w2,_h2) in eyes:\n",
    "        if _w2 * _h2 > maxArea2:\n",
    "            x2=_x2\n",
    "            y2=_y2\n",
    "            w2=_w2\n",
    "            h2=_h2\n",
    "        maxArea2=w2*h2\n",
    "\n",
    "    if maxArea2>0:\n",
    "        #cv2.rectangle(resultImage,(x2-2,y2-2),(x2+w2+2,y2+h2+2),eyeColor,2)\n",
    "        cv2.ellipse(resultImage, (x2+int(round(w2/2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) # Left eye      \n",
    "        cv2.ellipse(resultImage, (x2+int(round(w2*2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) # Right eye\n",
    "       \n",
    "    largeResult = cv2.resize(resultImage,(OUTPUT_SIZE_WIDTH, OUTPUT_SIZE_HEIGHT))\n",
    "\n",
    "    cv2.imshow(\"Detect Face and Eyes (Press 'Esc' to exit)\",largeResult)\n",
    "\n",
    "\n",
    "# When everything done, release the capture\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code below is a simple face adetection from camera source and cartoonify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code is tracks your face (from camera) and cartoonify it\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "OUTPUT_SIZE_WIDTH = 900\n",
    "OUTPUT_SIZE_HEIGHT = 600\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "while(True):\n",
    "    faceColor = (0,100,255)\n",
    "    eyeColor = (0,200,255)\n",
    "\n",
    "    rc, fullSizeBaseImage = capture.read()\n",
    "    fullSizeBaseImage = cv2.flip(fullSizeBaseImage,1)\n",
    "    baseImage = fullSizeBaseImage\n",
    "    \n",
    "    pressedKey = cv2.waitKey(2)\n",
    "    if(pressedKey == ord(' ')) | (pressedKey == 27):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        #exit(0)\n",
    "    resultImage = baseImage.copy()\n",
    "\n",
    "    gray_image=cv2.cvtColor(baseImage,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray_image,1.1,8)\n",
    "    eyes = eyeCascade.detectMultiScale(gray_image,1.1,8)\n",
    "    \n",
    "    maxArea=0\n",
    "    x=0\n",
    "    y=0\n",
    "    w=0\n",
    "    h=0\n",
    "    \n",
    "    maxArea2=0\n",
    "    x2=0\n",
    "    y2=0\n",
    "    w2=0\n",
    "    h2=0\n",
    "    \n",
    "    for (_x, _y,_w,_h) in faces:\n",
    "        if _w * _h > maxArea:\n",
    "            x=_x\n",
    "            y=_y\n",
    "            w=_w\n",
    "            h=_h\n",
    "        maxArea=w*h\n",
    "    \n",
    "    #h1, w1 = resultImage.shape[:2]\n",
    "\n",
    "    for (_x2, _y2,_w2,_h2) in eyes:\n",
    "        if _w2 * _h2 > maxArea2:\n",
    "            x2=_x2\n",
    "            y2=_y2\n",
    "            w2=_w2\n",
    "            h2=_h2\n",
    "        maxArea2=w2*h2\n",
    "    \n",
    "    if maxArea>0 and maxArea2>0:\n",
    "        #overlay = cv2.rectangle(resultImage,(x,y),(x+w,y+h),faceColor,2)\n",
    "        overlay = cv2.ellipse(resultImage, (x+int(round(w/2,0)),y+int(round(h/2,0))), (int(round(w/2,0)),int(round(h/2,0))), 0,0,360,faceColor,2)\n",
    "        original_overlay = baseImage\n",
    "\n",
    "        overlay = cv2.ellipse(resultImage, (x2+int(round(w2/2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) # Left eye\n",
    "        overlay = cv2.ellipse(resultImage, (x2+int(round(w2*2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) # Right eye\n",
    "\n",
    "        # Image Frame transformation\n",
    "        #ellipse_overlay = cv2.ellipse(resultImage, (x+int(round(w/2,0)),y+int(round(h/2,0))), (int(round(w/2,0)),int(round(h/2,0))), 0,0,360,faceColor,2)    \n",
    "        colorImage = cv2.bilateralFilter(overlay, 9, 250, 250)\n",
    "        \n",
    "        # Detect Edges\n",
    "        img_gray = cv2.cvtColor(overlay, cv2.COLOR_RGB2GRAY) \n",
    "        img_blur = cv2.medianBlur(img_gray, 9) \n",
    "        img_edge = cv2.adaptiveThreshold(img_blur, 255, \n",
    "                                        cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                        cv2.THRESH_BINARY, 15, 3)\n",
    "        (x1,y1,z1) = resultImage.shape \n",
    "        \n",
    "        img_edge = cv2.resize(img_edge,(y1,x1)) \n",
    "        img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
    "        img_cartoon = cv2.bitwise_and(colorImage,img_edge)\n",
    "                \n",
    "        # Color Quantization\n",
    "        reducedColorImage=np.float32(img_cartoon).reshape((-1,3))\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,5,0.0001)\n",
    "        ret,label,center=cv2.kmeans(reducedColorImage,16,None,criteria,5,cv2.KMEANS_RANDOM_CENTERS) # slow performance\n",
    "        center=np.uint8(center)\n",
    "        img_edge=center[label.flatten()]\n",
    "        img_cartoon=img_edge.reshape(img_cartoon.shape)\n",
    "    else:\n",
    "        overlay = resultImage\n",
    "        colorImage = resultImage\n",
    "        img_edge = resultImage\n",
    "        img_cartoon = resultImage\n",
    "                \n",
    "    # estimate using rectangle shape and superimpose on original frame\n",
    "\n",
    "    # Cartoon Effect on Face but not on Eyes\n",
    "    if (x<x+int(round(w/2,0))) and (y<y+int(round(h,0))) and (x+int(round(w/2,0))<x+w) and (y+int(round(h,0))<y+int(round(h*2,0))):\n",
    "        overlay[y:y+int(round(h,0)),x:x+w,:] = img_cartoon[y:y+int(round(h,0)),x:x+w,:]\n",
    "    if (x2<x2+int(round(w2/2,0))) and (y2<y2+int(round(h2,0))) and (x2+int(round(w2/2,0))<x2+w2) and (y2+int(round(h2,0))<y2+int(round(h2*2,0))):\n",
    "        overlay[y2:y2+int(round(h2,0)),x2:x2+int(round(w2,0)),:] = baseImage[y2:y2+int(round(h2,0)),x2:x2+int(round(w2,0)),:] # Left eye\n",
    "        overlay[y2:y2+int(round(h2,0)),x2+int(round(w2*1.5,0)):x2+int(round(w2*2.5,0)),:] = baseImage[y2:y2+int(round(h2,0)),x2+int(round(w2*1.5,0)):x2+int(round(w2*2.5,0)),:] # Right eye\n",
    "    \n",
    "    # Draw Ellipse on Face Area    \n",
    "    overlay = cv2.ellipse(overlay, (x+int(round(w/2,0)),y+int(round(h/2,0))), (int(round(w/2,0)),int(round(h/2,0))), 0,0,360,faceColor,2)\n",
    "    # Draw Ellipse on Eye Area\n",
    "    overlay = cv2.ellipse(overlay, (x2+int(round(w2/2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) # Left eye\n",
    "    overlay = cv2.ellipse(overlay, (x2+int(round(w2*2,0)),y2+int(round(h2/2,0))), (int(round(w2/2,0)),int(round(h2/2,0))), 0,0,360,eyeColor,2) # Right eye\n",
    "     \n",
    "    resultImage = overlay\n",
    "    \n",
    "    largeResult = cv2.resize(resultImage,(OUTPUT_SIZE_WIDTH, OUTPUT_SIZE_HEIGHT))\n",
    "    cv2.imshow(\"Cartoonify Face (Press 'Esc' to exit)\",largeResult)\n",
    "\n",
    "# When everything done, release the capture\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
